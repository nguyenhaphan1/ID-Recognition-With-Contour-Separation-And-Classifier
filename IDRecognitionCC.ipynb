{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nguyenhaphan1/ID-Recognition-With-Contour-Separation-And-Classifier/blob/main/IDRecognitionCC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oFuJkYfJw0tt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15b3bb11-9711-4e68-b660-0d7accab553b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.15.1 keras==2.15.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "d9SdoBPhx9xK",
        "outputId": "103bb756-b4bb-4eef-f3d8-efb26d6b86d1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.15.1\n",
            "  Downloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting keras==2.15.0\n",
            "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow==2.15.1)\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (4.12.2)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.15.1)\n",
            "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (1.64.1)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow==2.15.1)\n",
            "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow==2.15.1)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.1) (0.44.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.0.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.2.2)\n",
            "Downloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, tensorflow-estimator, ml-dtypes, keras, tensorboard, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.16.0\n",
            "    Uninstalling wrapt-1.16.0:\n",
            "      Successfully uninstalled wrapt-1.16.0\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.0\n",
            "    Uninstalling ml-dtypes-0.4.0:\n",
            "      Successfully uninstalled ml-dtypes-0.4.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.4.1\n",
            "    Uninstalling keras-3.4.1:\n",
            "      Successfully uninstalled keras-3.4.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.0\n",
            "    Uninstalling tensorboard-2.17.0:\n",
            "      Successfully uninstalled tensorboard-2.17.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.0\n",
            "    Uninstalling tensorflow-2.17.0:\n",
            "      Successfully uninstalled tensorflow-2.17.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.15.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-2.15.0 ml-dtypes-0.3.2 tensorboard-2.15.2 tensorflow-2.15.1 tensorflow-estimator-2.15.0 wrapt-1.14.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras",
                  "ml_dtypes",
                  "tensorflow",
                  "wrapt"
                ]
              },
              "id": "c424dc231d884cf5a95e79daae0cf68e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import shutil\n",
        "from google.colab.patches import cv2_imshow\n",
        "import warnings\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "uygdXEB2xmj-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhYWhT2_x5cL",
        "outputId": "76fe625e-cccb-4643-b1bd-64f72d226953"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.1\n",
            "2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = tf.keras.models.load_model('/content/drive/MyDrive/CCCD/digit_classification.keras')"
      ],
      "metadata": {
        "id": "Rbt1wt0kxojJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_bounding_box_with_contour(img, contour):\n",
        "  x, y, w, h = cv2.boundingRect(contour)\n",
        "  cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "def draw_bounding_box_with_bbox(img, bbox):\n",
        "  cv2.rectangle(img, (bbox[0], bbox[1]), (bbox[0] + bbox[2], bbox[1] + bbox[3]), (0, 255, 0), 1)\n",
        "  return img\n",
        "\n",
        "def finding_narrowest_position(contours):\n",
        "  narrowest_distance = 999\n",
        "  narrowest_position = 0\n",
        "\n",
        "  while(len(contours) > 0):\n",
        "    x_cnt = []\n",
        "    idx = 0\n",
        "    x_value = contours[idx][0]\n",
        "    # print(f\"X value: {x_value}\")\n",
        "\n",
        "    while(idx < len(contours)):\n",
        "      if contours[idx][0] == x_value:\n",
        "        x_cnt.append(contours[idx])\n",
        "        idx += 1\n",
        "      else:\n",
        "        break\n",
        "\n",
        "    x_cnt = sorted(x_cnt, key=lambda x:x[1])\n",
        "    cnt_distance = x_cnt[-1][1] - x_cnt[0][1]\n",
        "\n",
        "    if cnt_distance < narrowest_distance:\n",
        "      narrowest_distance = cnt_distance\n",
        "      narrowest_position = x_value\n",
        "\n",
        "    contours = contours[idx:]\n",
        "\n",
        "  return narrowest_position\n",
        "\n",
        "\n",
        "def digits_recognition(bboxes, model, target_size, img):\n",
        "\n",
        "  digits = \"\"\n",
        "  for bbox in bboxes:\n",
        "    x, y, w, h = bbox\n",
        "    digit_img = img[y:y+h, x:x+w]\n",
        "    digit_img = cv2.resize(digit_img, (target_size, target_size))\n",
        "    digit_img = digit_img.reshape(1, target_size, target_size, 3)\n",
        "    prob = model.predict(digit_img, verbose=False)\n",
        "    digits += str(np.argmax(prob))\n",
        "\n",
        "  return digits"
      ],
      "metadata": {
        "id": "JRGjQ6iYx1GR"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Threshold ratios and constants\n",
        "min_ratios = {\n",
        "    \"single\": 0.036231884057971016,\n",
        "    \"two\": 0.13559322033898305,\n",
        "    \"three\": 0.21008403361344538,\n",
        "    \"four\": 0.29411764705882354,\n",
        "    \"five\": 0.3813559322033898,\n",
        "    \"six\": 0.4491525423728814,\n",
        "    \"seven\": 0.5289256198347108,\n",
        "    \"eight\": 0.625,\n",
        "    \"nine\": 0.7,\n",
        "    \"ten\": 0.7844827586206896\n",
        "}\n",
        "min_area = 999\n",
        "min_ratio_height = 0.5428571428571428  # Adjusted initial height threshold ratio\n",
        "\n",
        "# Function to draw contours and process images\n",
        "def process_image(image_path):\n",
        "    global correct_separation, incorrect_separation, min_ratio_height, saved_file\n",
        "\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        return\n",
        "\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    image_width, image_height = img_gray.shape[1], img_gray.shape[0]\n",
        "    image_area = image_height * image_width\n",
        "\n",
        "    thresh1 = cv2.adaptiveThreshold(img_gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 93, 19)\n",
        "    thresh1 = cv2.bitwise_not(thresh1)\n",
        "\n",
        "    contours, _ = cv2.findContours(thresh1, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    bboxes = [cv2.boundingRect(contour) for contour in contours if cv2.moments(contour)[\"m00\"] != 0]\n",
        "    bboxes.sort(key=lambda x: x[0])\n",
        "\n",
        "    # Flatten contours for further calculations\n",
        "    flatten_contours = np.concatenate(contours, axis=0).reshape((-1, 2))\n",
        "\n",
        "    # Detect digits in bounding boxes\n",
        "    true_bboxes = detect_digits(bboxes, flatten_contours, image_width, image_height, img_gray)\n",
        "\n",
        "    # Evaluate detection\n",
        "    if evaluate_detection(true_bboxes, image_height):\n",
        "      result = digits_recognition(true_bboxes, classifier, target_size=32, img=img_rgb)\n",
        "      print(f\"Result: {result}\")\n",
        "      print()\n",
        "\n",
        "# Function to detect digits within bounding boxes\n",
        "def detect_digits(bboxes, flatten_contours, image_width, image_height, img_gray):\n",
        "    true_bboxes = []\n",
        "\n",
        "    for bbox in bboxes:\n",
        "        ratio_width = bbox[2] / image_width\n",
        "        ratio_height = bbox[3] / image_height\n",
        "        x, y, w, h = bbox\n",
        "        if ratio_height >= min_ratio_height:\n",
        "            if min_ratios[\"single\"] <= ratio_width < min_ratios[\"two\"]:\n",
        "                true_bboxes.append(bbox)\n",
        "                min_ratios[\"single\"] = min(min_ratios[\"single\"], ratio_width)\n",
        "            elif min_ratios[\"two\"] <= ratio_width < min_ratios[\"three\"]:\n",
        "                true_bboxes.extend(separate_bbox(bbox, flatten_contours, [0.25, 0.75]))\n",
        "                min_ratios[\"two\"] = min(min_ratios[\"two\"], ratio_width)\n",
        "            elif min_ratios[\"three\"] <= ratio_width < min_ratios[\"four\"]:\n",
        "                true_bboxes.extend(separate_bbox(bbox, flatten_contours, [1/6, 1/2, 5/6], separate_into=3))\n",
        "                min_ratios[\"three\"] = min(min_ratios[\"three\"], ratio_width)\n",
        "            elif min_ratios[\"four\"] <= ratio_width < min_ratios[\"five\"]:\n",
        "                true_bboxes.extend(separate_bbox(bbox, flatten_contours, [1/8, 3/8, 5/8, 7/8], separate_into=4))\n",
        "                min_ratios[\"four\"] = min(min_ratios[\"four\"], ratio_width)\n",
        "            elif min_ratios[\"five\"] <= ratio_width < min_ratios[\"six\"]:\n",
        "                true_bboxes.extend(separate_bbox(bbox, flatten_contours, [1/10, 3/10, 1/2, 7/10, 9/10], separate_into=5))\n",
        "            elif min_ratios[\"six\"] <= ratio_width < min_ratios[\"seven\"]:\n",
        "                true_bboxes.extend(separate_bbox(bbox, flatten_contours, [1/12, 3/12, 5/12, 7/12, 9/12, 11/12], separate_into=6))\n",
        "            elif min_ratios[\"seven\"] <= ratio_width < min_ratios[\"eight\"]:\n",
        "                true_bboxes.extend(separate_bbox(bbox, flatten_contours, [1/14, 3/14, 5/14, 7/14, 9/14, 11/14, 13/14], separate_into=7))\n",
        "            elif min_ratios[\"eight\"] <= ratio_width < min_ratios[\"nine\"]:\n",
        "                true_bboxes.extend(separate_bbox(bbox, flatten_contours, [1/16, 3/16, 5/16, 7/16, 9/16, 11/16, 13/16, 15/16], separate_into=8))\n",
        "            elif min_ratios[\"nine\"] <= ratio_width < min_ratios[\"ten\"]:\n",
        "                true_bboxes.extend(separate_bbox(bbox, flatten_contours, [1/18, 3/18, 5/18, 7/18, 9/18, 11/18, 13/18, 15/18, 17/18], separate_into=9))\n",
        "            elif min_ratios[\"ten\"] <= ratio_width < 0.8:\n",
        "                true_bboxes.extend(separate_bbox(bbox, flatten_contours, [1/20, 3/20, 5/20, 7/20, 9/20, 11/20, 13/20, 15/20, 17/20, 19/20], separate_into=10))\n",
        "        else:\n",
        "            print(\"Not match height of a digit\")\n",
        "\n",
        "    return true_bboxes\n",
        "\n",
        "# Function to separate bounding boxes\n",
        "def separate_bbox(bbox, flatten_contours, positions, separate_into=2):\n",
        "    result_bboxes = []\n",
        "    contours = [sorted([[x, y] for x, y in flatten_contours if bbox[0] + pos[0]*bbox[2] < x < bbox[0] + pos[1]*bbox[2]], key=lambda x: x[0]) for pos in zip(positions[:-1], positions[1:])]\n",
        "\n",
        "    x_divides = [finding_narrowest_position(contour) for contour in contours]\n",
        "    x_divides = [bbox[0]] + x_divides + [bbox[0] + bbox[2]]\n",
        "\n",
        "    for i in range(separate_into):\n",
        "        result_bboxes.append((x_divides[i], bbox[1], x_divides[i+1] - x_divides[i], bbox[3]))\n",
        "\n",
        "    return result_bboxes\n",
        "\n",
        "# Function to evaluate the detection results\n",
        "def evaluate_detection(true_bboxes, image_height):\n",
        "    global correct_separation, incorrect_separation, min_ratio_height\n",
        "\n",
        "    if len(true_bboxes) == 12:\n",
        "        min_ratio_height = min(min_ratio_height, min([bbox[3] / image_height for bbox in true_bboxes]))\n",
        "        return True\n",
        "    else:\n",
        "        print(f\"Wrong separation: Length: {len(true_bboxes)}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "image_path = '/content/drive/MyDrive/CCCD/data_for_prediction/new_ids_separation2/id_15.jpg'\n",
        "process_image(image_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2Qag7rCuyvjv",
        "outputId": "9d98c36e-70c9-4cc0-fdc7-80aebcb63e96"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: 030093009624\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XfFv-Y1vzEBB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}